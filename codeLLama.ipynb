{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 .First open the terminal and run this command\n",
    "# sudo apt-get install build-essential g++ clang\n",
    "\n",
    "# 2. Install LlamaCpp i face lots of issue but this 0.2.77 version is work fine\n",
    "# !pip install llama-cpp-python==0.2.77\n",
    "\n",
    "\n",
    "!pip install openai tiktoken  langchain langchain-community GitPython gpt4all llama-cpp-python==0.2.77  langchain-qdrant -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ./suyo_repo already exists. Pulling latest changes...\n",
      "Repository cloned/updated successfully.\n",
      "Number of documents loaded: 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from git import Repo, GitCommandError\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "\n",
    "repo_url = \"https://github.com/SuyodhanJ6/LLM-workshop-2024\"\n",
    "repo_path = \"./suyo_repo\"  # Changed to a relative path\n",
    "\n",
    "try:\n",
    "    # Check if the directory already exists\n",
    "    if os.path.exists(repo_path):\n",
    "        print(f\"Directory {repo_path} already exists. Pulling latest changes...\")\n",
    "        repo = Repo(repo_path)\n",
    "        origin = repo.remotes.origin\n",
    "        origin.pull()\n",
    "    else:\n",
    "        print(f\"Cloning repository to {repo_path}...\")\n",
    "        repo = Repo.clone_from(repo_url, repo_path)\n",
    "    \n",
    "    print(\"Repository cloned/updated successfully.\")\n",
    "\n",
    "    loader = GenericLoader.from_filesystem(\n",
    "        repo_path,\n",
    "        glob=\"**/*\",\n",
    "        suffixes=[\".py\"],\n",
    "        parser=LanguageParser(language=Language.PYTHON, parser_threshold=500)\n",
    "    )\n",
    "    documents = loader.load()\n",
    "    print(f\"Number of documents loaded: {len(documents)}\")\n",
    "\n",
    "except GitCommandError as e:\n",
    "    print(f\"Git error occurred: {e}\")\n",
    "    print(\"Please check your internet connection and repository access.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import Language\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.PYTHON,\n",
    "                                                               chunk_size=2000,\n",
    "                                                               chunk_overlap=200)\n",
    "texts = python_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'suyo_repo/02_data/supplementary.py', 'language': <Language.PYTHON: 'python'>}, page_content='# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\\n# Source for \"Build a Large Language Model From Scratch\"\\n#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\\n# Code: https://github.com/rasbt/LLMs-from-scratch\\n\\nimport torch\\nimport tiktoken\\nfrom torch.utils.data import Dataset, DataLoader\\n\\n\\nclass GPTDatasetV1(Dataset):\\n    def __init__(self, txt, tokenizer, max_length, stride):\\n        self.input_ids = []\\n        self.target_ids = []\\n\\n        # Tokenize the entire text\\n        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\\n\\n        # Use a sliding window to chunk the book into overlapping sequences of max_length\\n        for i in range(0, len(token_ids) - max_length, stride):\\n            input_chunk = token_ids[i:i + max_length]\\n            target_chunk = token_ids[i + 1: i + max_length + 1]\\n            self.input_ids.append(torch.tensor(input_chunk))\\n            self.target_ids.append(torch.tensor(target_chunk))\\n\\n    def __len__(self):\\n        return len(self.input_ids)\\n\\n    def __getitem__(self, idx):\\n        return self.input_ids[idx], self.target_ids[idx]\\n\\n\\ndef create_dataloader_v1(txt, batch_size=4, max_length=256, \\n                         stride=128, shuffle=True, drop_last=True,\\n                         num_workers=0):\\n\\n    # Initialize the tokenizer\\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\\n\\n    # Create dataset\\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\\n\\n    # Create dataloader\\n    dataloader = DataLoader(\\n        dataset,\\n        batch_size=batch_size,\\n        shuffle=shuffle,\\n        drop_last=drop_last,\\n        num_workers=num_workers\\n    )\\n\\n    return dataloader')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in GPT4AllEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0382995530962944, 0.1234196200966835, -0.028588155284523964, 0.05368538200855255, 0.008782053366303444, -0.039788126945495605, -0.0730057954788208, 0.04770145192742348, -0.0304920244961977, 0.05498405173420906, 0.08509133011102676, 0.036606401205062866, -0.005337036680430174, -0.002272902289405465, -0.06056099012494087, -0.027201388031244278, -0.011344251222908497, -0.042489923536777496, 0.009125489741563797, 0.1008230447769165, 0.07578961551189423, 0.06914955377578735, 0.009880030527710915, -0.0018218893092125654, 0.026144668459892273, 0.032788898795843124, -0.07189112901687622, 0.028421707451343536, 0.061703089624643326, -0.05254505202174187, 0.03358764573931694, 0.07441546767950058, 0.07543332874774933, 0.03536637872457504, 0.067121222615242, 0.010775715112686157, 0.0817243754863739, 0.016603022813796997, 0.032795388251543045, 0.036285385489463806, 0.002255137776955962, -0.09890527278184891, 0.005074367392808199, 0.050920628011226654, 0.009290034882724285, 0.024473417550325394, -0.06447196751832962, 0.001986687071621418, -0.07917290925979614, 0.02082391269505024, -0.019175663590431213, -0.02806960418820381, -0.0706271380186081, -0.007055060472339392, 0.010461397469043732, 0.03894023597240448, 0.01767812669277191, -0.01962459087371826, -0.020027365535497665, 0.01813577115535736, -0.00027622407651506364, 0.013001086190342903, -0.09334658086299896, 0.08445484191179276, 0.11705757677555084, 0.057487666606903076, -0.022515611723065376, -0.036857981234788895, -0.034456875175237656, -0.06383480876684189, -0.06858030706644058, -0.0055221011862158775, 0.044347673654556274, 0.01662043295800686, 0.0308713149279356, -0.019702842459082603, -0.024882236495614052, -0.05902477726340294, 0.09451894462108612, -0.06537432968616486, -0.05600987747311592, -0.032812152057886124, 0.008100779727101326, -0.0022063946817070246, 0.0019960098434239626, 0.07937905192375183, 0.08523858338594437, 0.007806591689586639, -0.013751191087067127, 0.031231967732310295, 0.010076138190925121, -0.032802511006593704, 0.007749010808765888, -0.006204516161233187, -0.05610258877277374, 0.004346801899373531, -0.014094309881329536, -0.03933735564351082, 0.07815960049629211, 0.07390197366476059, 0.05615142360329628, 0.003308808896690607, 0.041549038141965866, -0.010321647860109806, -0.13267958164215088, -0.10465389490127563, 0.018422162160277367, -0.07518777251243591, 0.04956900328397751, -0.028461499139666557, -0.013518360443413258, -0.03712650015950203, -0.06747423112392426, -0.019548514857888222, -0.010146091692149639, -0.05191416293382645, -0.05933348089456558, 0.01671723462641239, 0.04105916619300842, 0.0015424301382154226, 0.08090955018997192, 0.002621122868731618, -0.038632892072200775, -0.04695127159357071, -0.05853205546736717, -0.029484588652849197, 0.03880215436220169, -8.107986243792144e-33, -0.012983053922653198, -0.014452820643782616, -0.02228540927171707, 0.10567904263734818, 0.003694084705784917, 0.005964756943285465, -0.023713888600468636, 0.041192058473825455, -0.07418668270111084, 0.007049772888422012, 0.0017760692862793803, -0.03329310566186905, 0.006836864165961742, 0.046893488615751266, -0.03836245462298393, 0.05856570601463318, -0.08392184227705002, 0.1195976734161377, -0.02530415542423725, 0.02759617380797863, 0.024528110399842262, 0.01418713852763176, 0.012816413305699825, -0.0578332394361496, -0.031656526029109955, -0.002915229182690382, -0.02730250544846058, -0.02746119163930416, -0.034062519669532776, 0.020085562020540237, 0.02259458601474762, 0.03094518929719925, -0.045473821461200714, -0.0025050074327737093, 0.015115214511752129, 0.09672699123620987, 0.001753679127432406, -0.05400443449616432, 0.0025222194381058216, 0.006024535279721022, -0.0564134456217289, -0.02817978337407112, 0.06961916387081146, 0.0441293939948082, 0.039853740483522415, -0.04201916605234146, -0.0038707349449396133, -0.041561249643564224, 0.09478086233139038, 0.019031429663300514, -0.04008793830871582, 0.032532140612602234, 0.012526868842542171, -0.056294046342372894, 0.0446646511554718, 0.04920234903693199, 0.017483320087194443, 0.0532987006008625, -0.020875519141554832, 0.06148607283830643, -0.014854737557470798, 0.07424266636371613, -0.05763966962695122, 0.04989493638277054, -0.058910954743623734, -0.0005969488993287086, -0.10968082398176193, -0.06832011789083481, 0.13053736090660095, -0.011842498555779457, -0.01602761447429657, -0.021082350984215736, -0.007098819594830275, -0.016363326460123062, -0.01689044199883938, -0.04816576465964317, 0.01578463986515999, 0.030611850321292877, -0.004564046394079924, -0.038145340979099274, -0.04708431661128998, -0.08068325370550156, -0.011492251418530941, -0.05194593593478203, -0.04341018944978714, -0.01921946555376053, 0.0363941416144371, -0.06583765149116516, -0.014969672076404095, -0.09120704978704453, 0.03516170009970665, 0.019919009879231453, -0.05597713589668274, -0.04274916276335716, 0.11662657558917999, 4.754723671520469e-33, -0.04276830330491066, 0.010740445926785469, -0.08695780485868454, 0.11423094570636749, 0.02616248093545437, 0.008781463839113712, 0.08936914801597595, -0.0018858953844755888, -0.04553039371967316, 0.08437753468751907, 0.011049173772335052, 0.0003786538145504892, -0.0003376157255843282, -0.0016804687911644578, 0.0015798924723640084, -0.02526165172457695, -0.03787454590201378, -0.05467329919338226, 0.0043436577543616295, 0.016169000416994095, -0.047619860619306564, 0.11082760244607925, 0.04585011303424835, 0.07997462153434753, -0.006751387845724821, -0.010343008674681187, 0.006981663405895233, -0.09520911425352097, -0.014401542022824287, -0.013537577353417873, -0.00934536475688219, -0.002610615221783519, -0.1216992735862732, 0.07752655446529388, 0.009051154367625713, -0.10182756930589676, 0.13142795860767365, -0.04581615701317787, -0.009555983357131481, 0.024253129959106445, 0.04589967057108879, 0.08774437010288239, 0.05512537807226181, 0.04714689776301384, -0.02279893308877945, 0.055405955761671066, 0.03947913646697998, -0.06862400472164154, 0.07692351192235947, 0.02654888853430748, 0.013439123518764973, -0.03161842003464699, 0.02121121622622013, -0.02458893693983555, -0.09502565115690231, 0.05002497136592865, -0.07880060374736786, -0.04682916775345802, -0.009467226453125477, 0.06837581843137741, -0.019559836015105247, 0.08320022374391556, -0.001942467293702066, 0.07850175350904465, 0.009700022637844086, -0.08325442671775818, -0.08888412266969681, 0.026186682283878326, -0.0035236289259046316, 0.002087315544486046, 0.06751880049705505, -0.043469563126564026, -0.03119804337620735, -0.1055603101849556, 0.08164386451244354, -0.11700675636529922, 0.0012789121828973293, -0.04226098582148552, -0.02502068504691124, -0.053892042487859726, 0.04664255306124687, -0.004609931726008654, -0.04908401146531105, 0.05340594798326492, -0.016847435384988785, -0.018801582977175713, 0.0021197402384132147, 0.010574127547442913, -0.02839285507798195, 0.06326238811016083, -0.041808031499385834, 0.036524802446365356, -0.028516115620732307, 0.012342381291091442, -0.03108053281903267, -1.8282358738019866e-08, -0.03360802307724953, -0.010374993085861206, 0.006395573262125254, -0.033845871686935425, -0.03434988483786583, 0.04373709112405777, 0.0761176124215126, -0.05066636949777603, -0.06549400836229324, -0.0236775204539299, 0.05222000926733017, 0.008213876746594906, -0.05051938444375992, -0.004705063533037901, 0.04601573571562767, -0.048314496874809265, -0.007646961137652397, -0.024745158851146698, -0.05900563299655914, 0.021783573552966118, -0.03323096036911011, 0.026246802881360054, 0.01947818323969841, 0.02203231118619442, -0.027165088802576065, 0.07806836068630219, 0.0325813926756382, 0.10125700384378433, 0.007141435984522104, -0.031039757654070854, 0.04085954651236534, 0.10804925858974457, -0.009380556643009186, -0.010245280340313911, 0.03722497448325157, 0.11906515061855316, 0.049847304821014404, 0.05208028107881546, 0.020204784348607063, 0.0556597001850605, -0.10270656645298004, -0.009892641566693783, -0.0225272998213768, 0.033140357583761215, 0.05215393006801605, -0.02946033515036106, -0.13836415112018585, -0.014179686084389687, -0.03768077865242958, -0.08340385556221008, -0.003492785384878516, -0.04154934361577034, 0.04904523864388466, 0.021510552614927292, -0.04018886759877205, 0.008461232297122478, 0.046618424355983734, -0.004042220767587423, -0.03810041397809982, -0.015196031890809536, 0.12493929266929626, 0.08800849318504333, 0.08595926314592361, -0.015370325185358524]\n",
      "[[-0.0382995530962944, 0.1234196200966835, -0.028588155284523964, 0.05368538200855255, 0.008782053366303444, -0.039788126945495605, -0.0730057954788208, 0.04770145192742348, -0.0304920244961977, 0.05498405173420906, 0.08509133011102676, 0.036606401205062866, -0.005337036680430174, -0.002272902289405465, -0.06056099012494087, -0.027201388031244278, -0.011344251222908497, -0.042489923536777496, 0.009125489741563797, 0.1008230447769165, 0.07578961551189423, 0.06914955377578735, 0.009880030527710915, -0.0018218893092125654, 0.026144668459892273, 0.032788898795843124, -0.07189112901687622, 0.028421707451343536, 0.061703089624643326, -0.05254505202174187, 0.03358764573931694, 0.07441546767950058, 0.07543332874774933, 0.03536637872457504, 0.067121222615242, 0.010775715112686157, 0.0817243754863739, 0.016603022813796997, 0.032795388251543045, 0.036285385489463806, 0.002255137776955962, -0.09890527278184891, 0.005074367392808199, 0.050920628011226654, 0.009290034882724285, 0.024473417550325394, -0.06447196751832962, 0.001986687071621418, -0.07917290925979614, 0.02082391269505024, -0.019175663590431213, -0.02806960418820381, -0.0706271380186081, -0.007055060472339392, 0.010461397469043732, 0.03894023597240448, 0.01767812669277191, -0.01962459087371826, -0.020027365535497665, 0.01813577115535736, -0.00027622407651506364, 0.013001086190342903, -0.09334658086299896, 0.08445484191179276, 0.11705757677555084, 0.057487666606903076, -0.022515611723065376, -0.036857981234788895, -0.034456875175237656, -0.06383480876684189, -0.06858030706644058, -0.0055221011862158775, 0.044347673654556274, 0.01662043295800686, 0.0308713149279356, -0.019702842459082603, -0.024882236495614052, -0.05902477726340294, 0.09451894462108612, -0.06537432968616486, -0.05600987747311592, -0.032812152057886124, 0.008100779727101326, -0.0022063946817070246, 0.0019960098434239626, 0.07937905192375183, 0.08523858338594437, 0.007806591689586639, -0.013751191087067127, 0.031231967732310295, 0.010076138190925121, -0.032802511006593704, 0.007749010808765888, -0.006204516161233187, -0.05610258877277374, 0.004346801899373531, -0.014094309881329536, -0.03933735564351082, 0.07815960049629211, 0.07390197366476059, 0.05615142360329628, 0.003308808896690607, 0.041549038141965866, -0.010321647860109806, -0.13267958164215088, -0.10465389490127563, 0.018422162160277367, -0.07518777251243591, 0.04956900328397751, -0.028461499139666557, -0.013518360443413258, -0.03712650015950203, -0.06747423112392426, -0.019548514857888222, -0.010146091692149639, -0.05191416293382645, -0.05933348089456558, 0.01671723462641239, 0.04105916619300842, 0.0015424301382154226, 0.08090955018997192, 0.002621122868731618, -0.038632892072200775, -0.04695127159357071, -0.05853205546736717, -0.029484588652849197, 0.03880215436220169, -8.107986243792144e-33, -0.012983053922653198, -0.014452820643782616, -0.02228540927171707, 0.10567904263734818, 0.003694084705784917, 0.005964756943285465, -0.023713888600468636, 0.041192058473825455, -0.07418668270111084, 0.007049772888422012, 0.0017760692862793803, -0.03329310566186905, 0.006836864165961742, 0.046893488615751266, -0.03836245462298393, 0.05856570601463318, -0.08392184227705002, 0.1195976734161377, -0.02530415542423725, 0.02759617380797863, 0.024528110399842262, 0.01418713852763176, 0.012816413305699825, -0.0578332394361496, -0.031656526029109955, -0.002915229182690382, -0.02730250544846058, -0.02746119163930416, -0.034062519669532776, 0.020085562020540237, 0.02259458601474762, 0.03094518929719925, -0.045473821461200714, -0.0025050074327737093, 0.015115214511752129, 0.09672699123620987, 0.001753679127432406, -0.05400443449616432, 0.0025222194381058216, 0.006024535279721022, -0.0564134456217289, -0.02817978337407112, 0.06961916387081146, 0.0441293939948082, 0.039853740483522415, -0.04201916605234146, -0.0038707349449396133, -0.041561249643564224, 0.09478086233139038, 0.019031429663300514, -0.04008793830871582, 0.032532140612602234, 0.012526868842542171, -0.056294046342372894, 0.0446646511554718, 0.04920234903693199, 0.017483320087194443, 0.0532987006008625, -0.020875519141554832, 0.06148607283830643, -0.014854737557470798, 0.07424266636371613, -0.05763966962695122, 0.04989493638277054, -0.058910954743623734, -0.0005969488993287086, -0.10968082398176193, -0.06832011789083481, 0.13053736090660095, -0.011842498555779457, -0.01602761447429657, -0.021082350984215736, -0.007098819594830275, -0.016363326460123062, -0.01689044199883938, -0.04816576465964317, 0.01578463986515999, 0.030611850321292877, -0.004564046394079924, -0.038145340979099274, -0.04708431661128998, -0.08068325370550156, -0.011492251418530941, -0.05194593593478203, -0.04341018944978714, -0.01921946555376053, 0.0363941416144371, -0.06583765149116516, -0.014969672076404095, -0.09120704978704453, 0.03516170009970665, 0.019919009879231453, -0.05597713589668274, -0.04274916276335716, 0.11662657558917999, 4.754723671520469e-33, -0.04276830330491066, 0.010740445926785469, -0.08695780485868454, 0.11423094570636749, 0.02616248093545437, 0.008781463839113712, 0.08936914801597595, -0.0018858953844755888, -0.04553039371967316, 0.08437753468751907, 0.011049173772335052, 0.0003786538145504892, -0.0003376157255843282, -0.0016804687911644578, 0.0015798924723640084, -0.02526165172457695, -0.03787454590201378, -0.05467329919338226, 0.0043436577543616295, 0.016169000416994095, -0.047619860619306564, 0.11082760244607925, 0.04585011303424835, 0.07997462153434753, -0.006751387845724821, -0.010343008674681187, 0.006981663405895233, -0.09520911425352097, -0.014401542022824287, -0.013537577353417873, -0.00934536475688219, -0.002610615221783519, -0.1216992735862732, 0.07752655446529388, 0.009051154367625713, -0.10182756930589676, 0.13142795860767365, -0.04581615701317787, -0.009555983357131481, 0.024253129959106445, 0.04589967057108879, 0.08774437010288239, 0.05512537807226181, 0.04714689776301384, -0.02279893308877945, 0.055405955761671066, 0.03947913646697998, -0.06862400472164154, 0.07692351192235947, 0.02654888853430748, 0.013439123518764973, -0.03161842003464699, 0.02121121622622013, -0.02458893693983555, -0.09502565115690231, 0.05002497136592865, -0.07880060374736786, -0.04682916775345802, -0.009467226453125477, 0.06837581843137741, -0.019559836015105247, 0.08320022374391556, -0.001942467293702066, 0.07850175350904465, 0.009700022637844086, -0.08325442671775818, -0.08888412266969681, 0.026186682283878326, -0.0035236289259046316, 0.002087315544486046, 0.06751880049705505, -0.043469563126564026, -0.03119804337620735, -0.1055603101849556, 0.08164386451244354, -0.11700675636529922, 0.0012789121828973293, -0.04226098582148552, -0.02502068504691124, -0.053892042487859726, 0.04664255306124687, -0.004609931726008654, -0.04908401146531105, 0.05340594798326492, -0.016847435384988785, -0.018801582977175713, 0.0021197402384132147, 0.010574127547442913, -0.02839285507798195, 0.06326238811016083, -0.041808031499385834, 0.036524802446365356, -0.028516115620732307, 0.012342381291091442, -0.03108053281903267, -1.8282358738019866e-08, -0.03360802307724953, -0.010374993085861206, 0.006395573262125254, -0.033845871686935425, -0.03434988483786583, 0.04373709112405777, 0.0761176124215126, -0.05066636949777603, -0.06549400836229324, -0.0236775204539299, 0.05222000926733017, 0.008213876746594906, -0.05051938444375992, -0.004705063533037901, 0.04601573571562767, -0.048314496874809265, -0.007646961137652397, -0.024745158851146698, -0.05900563299655914, 0.021783573552966118, -0.03323096036911011, 0.026246802881360054, 0.01947818323969841, 0.02203231118619442, -0.027165088802576065, 0.07806836068630219, 0.0325813926756382, 0.10125700384378433, 0.007141435984522104, -0.031039757654070854, 0.04085954651236534, 0.10804925858974457, -0.009380556643009186, -0.010245280340313911, 0.03722497448325157, 0.11906515061855316, 0.049847304821014404, 0.05208028107881546, 0.020204784348607063, 0.0556597001850605, -0.10270656645298004, -0.009892641566693783, -0.0225272998213768, 0.033140357583761215, 0.05215393006801605, -0.02946033515036106, -0.13836415112018585, -0.014179686084389687, -0.03768077865242958, -0.08340385556221008, -0.003492785384878516, -0.04154934361577034, 0.04904523864388466, 0.021510552614927292, -0.04018886759877205, 0.008461232297122478, 0.046618424355983734, -0.004042220767587423, -0.03810041397809982, -0.015196031890809536, 0.12493929266929626, 0.08800849318504333, 0.08595926314592361, -0.015370325185358524]]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
    "gpt4all_kwargs = {'allow_download': 'True'}\n",
    "gpt4all_embd = GPT4AllEmbeddings(model_name=model_name,\n",
    "    gpt4all_kwargs=gpt4all_kwargs)\n",
    "\n",
    "text = \"This is a test document.\"\n",
    "\n",
    "query_result = gpt4all_embd.embed_query(text)\n",
    "\n",
    "doc_result = gpt4all_embd.embed_documents([text])\n",
    "\n",
    "print(query_result)\n",
    "print(doc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, ConversationalRetrievalChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the GPT4AllEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
    "gpt4all_kwargs = {'allow_download': 'True'}\n",
    "embeddings = GPT4AllEmbeddings(model_name=model_name, gpt4all_kwargs=gpt4all_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Qdrant vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-memory Qdrant setup\n",
    "client = QdrantClient(\":memory:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"autogen_collection1\",\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"autogen_collection1\",\n",
    "    embedding=embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['58042e88a53e47c89a6b86ac278f399b',\n",
       " '6523314393634e74b5259987c9e24b5b',\n",
       " '1fe1d91084ec43f39100d9ccac6907d1',\n",
       " '05f4db023d6943c18be48f04e2ca4e3f',\n",
       " '492845fcd25448ad8ee40c1cd9e65cdc',\n",
       " '49b177e31f56446998e6338011034693',\n",
       " 'e984b5aa2f5548a295e5a6f99313f922',\n",
       " '002157d100b9462aae323362a3502559',\n",
       " '9f2231af78a14221a438d3aa8a29ecdc',\n",
       " '0cff688cf04d456cb31bc3a5578158f4',\n",
       " '130c4a8a1bdd43d8a45bcc2d9b776e4e',\n",
       " '7ce262908d0d48758b493ba2d1043664',\n",
       " '5b713b16dcce43f9823289503533278a',\n",
       " 'ee9dbe0fd6c144dd9e181a167a4d8eab',\n",
       " '9ec295a26bd142bb9feac26ddf74aec2',\n",
       " 'dfb96b9341b54bc9b4cd79db537edabd',\n",
       " 'd17c8a729b67434fb280426cc9111ef2',\n",
       " 'ab3c32db326d42af8174b08945b8a43e',\n",
       " 'df518dc9cd0d4246a6493edabdd7e517',\n",
       " '8f185c81b54f42458e694786080eefa6',\n",
       " 'b84faec44bfa492d9935c0b10cb1b487',\n",
       " 'ea8440d41d964cd8b988d80d9d0a0876',\n",
       " '0492331e3ce54f219053cab7af74b92c',\n",
       " '717ab0ad67404c39838030915a71b332',\n",
       " 'cf78d6d3cb104cb6bed8e21f69fa2707',\n",
       " '197600b90aff437585cf616d5e4cdad3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['QdrantVectorStore', 'GPT4AllEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x7ab7ac047670>, search_type='mmr', search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Code Analysis Question: {question}\n",
    "\n",
    "Analysis:\n",
    "Let's break this down step by step:\n",
    "\n",
    "1. Understand the question:\n",
    "   [Brief restatement of the question]\n",
    "\n",
    "2. Analyze the code or concept:\n",
    "   [Detailed analysis of the code or concept in question]\n",
    "\n",
    "3. Provide examples (if applicable):\n",
    "   [Relevant code examples or illustrations]\n",
    "\n",
    "4. Explain key points:\n",
    "   [Explanation of important aspects or potential issues]\n",
    "\n",
    "5. Best practices or improvements (if applicable):\n",
    "   [Suggestions for better coding practices or improvements]\n",
    "\n",
    "6. Conclusion:\n",
    "   [Summary of the analysis and main takeaways]\n",
    "\n",
    "Is there any specific part of this analysis you'd like me to elaborate on?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up LlamaCpp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 363 tensors from codellama-13b-instruct.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = codellama_codellama-13b-instruct-hf\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 16384\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32016]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32016]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32016]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_K:  241 tensors\n",
      "llama_model_loader: - type q6_K:   41 tensors\n",
      "llm_load_vocab: special tokens cache size = 259\n",
      "llm_load_vocab: token to piece cache size = 0.1686 MB\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32016\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 16384\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 16384\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 7.33 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = codellama_codellama-13b-instruct-hf\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: PRE token        = 32007 '▁<PRE>'\n",
      "llm_load_print_meta: SUF token        = 32008 '▁<SUF>'\n",
      "llm_load_print_meta: MID token        = 32009 '▁<MID>'\n",
      "llm_load_print_meta: EOT token        = 32010 '▁<EOT>'\n",
      "llm_load_tensors: ggml ctx size =    0.18 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  7500.96 MiB\n",
      "....................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 5024\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  3925.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 3925.00 MiB, K (f16): 1962.50 MiB, V (f16): 1962.50 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   442.32 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '1000000.000000', 'llama.context_length': '16384', 'general.name': 'codellama_codellama-13b-instruct-hf', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '40', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "# callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "# llm = LlamaCpp(\n",
    "#     model_path=\"codellama-13b-instruct.Q4_K_M.gguf\",\n",
    "#     n_ctx=5000,\n",
    "#     n_gpu_layers=30,\n",
    "#     n_batch=512,\n",
    "#     f16_kv=True,\n",
    "#     callback_manager=callback_manager,\n",
    "#     verbose=True,\n",
    "# )\n",
    "n_gpu_layers = 1  # The number of layers to put on the GPU. The rest will be on the CPU. If you don't know how many layers there are, you can use -1 to move all to GPU.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"codellama-13b-instruct.Q4_K_M.gguf\",\n",
    "    n_ctx=5000,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = prompt | llm \n",
    "question = \"how to Preparing a dataset for supervised instruction finetuning?\"\n",
    "llm_chain.invoke({\"question\": question})\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain = prompt | llm | StrOutputParser() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(llm=llm,memory_key=\"chat_history\", return_messages=True)  # prompt\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Preparing a dataset for supervised instruction finetuning can be done in the following steps.\n",
      "\n",
      "1. Determine which task (e.g., \"text-to-image\" or \"text-to-video\") and which model (e.g., \"GPT2\" or \"BART\") to use for fine-tuning.\n",
      "\n",
      "\n",
      "\n",
      "2. Acquire the dataset(s) needed to perform fine-tuning. The specific steps that need to be followed in order to acquire the dataset(s) needed to perform fine-tuning will depend on the specific task and model being used, as well as other factors such as the size of the dataset required to perform fine-tuning (e.g., \"full\" or \"partial\")).\n",
      "\n",
      "\n",
      "\n",
      "3. Preprocess the acquired dataset(s)) to create a format that is suitable for use with fine-tuning. The specific steps that need to be followed in order to preprocess the acquired dataset(s)) will depend on the specific task and model being used, as well as other factors such as the size of the dataset required to perform fine-tuning (e.g., \"full\" or \"partial\")"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   11170.36 ms\n",
      "llama_print_timings:      sample time =     322.94 ms /   256 runs   (    1.26 ms per token,   792.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   48495.75 ms /     2 tokens (24247.88 ms per token,     0.04 tokens per second)\n",
      "llama_print_timings:        eval time =  447607.10 ms /   255 runs   ( 1755.32 ms per token,     0.57 tokens per second)\n",
      "llama_print_timings:       total time =  452374.34 ms /   257 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The human asks how to prepare a dataset for supervised instruction finetuning. The AI respond"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow to Preparing a dataset for supervised instruction finetuning?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mqa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/chains/base.py:165\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[0;32m--> 165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/chains/base.py:466\u001b[0m, in \u001b[0;36mChain.prep_outputs\u001b[0;34m(self, inputs, outputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_outputs(outputs)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_only_outputs:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/memory/summary.py:113\u001b[0m, in \u001b[0;36mConversationSummaryMemory.save_context\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save context from this conversation to buffer.\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msave_context(inputs, outputs)\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_new_summary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/memory/summary.py:45\u001b[0m, in \u001b[0;36mSummarizerMixin.predict_new_summary\u001b[0;34m(self, messages, existing_summary)\u001b[0m\n\u001b[1;32m     38\u001b[0m new_lines \u001b[38;5;241m=\u001b[39m get_buffer_string(\n\u001b[1;32m     39\u001b[0m     messages,\n\u001b[1;32m     40\u001b[0m     human_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhuman_prefix,\n\u001b[1;32m     41\u001b[0m     ai_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_prefix,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     44\u001b[0m chain \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexisting_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_lines\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/chains/llm.py:316\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    302\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:179\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     emit_warning()\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/chains/llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain/chains/llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:752\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    746\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    750\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    751\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:946\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    932\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    933\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    934\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m         )\n\u001b[1;32m    945\u001b[0m     ]\n\u001b[0;32m--> 946\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:789\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    788\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    790\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:776\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    768\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    773\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    775\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 776\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    780\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    784\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    785\u001b[0m         )\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    787\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1510\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1507\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1509\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1510\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1512\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1513\u001b[0m     )\n\u001b[1;32m   1514\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain_community/llms/llamacpp.py:289\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     combined_text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    290\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    291\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    292\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    294\u001b[0m     ):\n\u001b[1;32m    295\u001b[0m         combined_text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/langchain_community/llms/llamacpp.py:342\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameters(stop), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    341\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(prompt\u001b[38;5;241m=\u001b[39mprompt, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    343\u001b[0m     logprobs \u001b[38;5;241m=\u001b[39m part[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    344\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m GenerationChunk(\n\u001b[1;32m    345\u001b[0m         text\u001b[38;5;241m=\u001b[39mpart[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    346\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs},\n\u001b[1;32m    347\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/llama_cpp/llama.py:1095\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1093\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1094\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1095\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m   1096\u001b[0m     prompt_tokens,\n\u001b[1;32m   1097\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m   1098\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m   1099\u001b[0m     min_p\u001b[38;5;241m=\u001b[39mmin_p,\n\u001b[1;32m   1100\u001b[0m     typical_p\u001b[38;5;241m=\u001b[39mtypical_p,\n\u001b[1;32m   1101\u001b[0m     temp\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m   1102\u001b[0m     tfs_z\u001b[38;5;241m=\u001b[39mtfs_z,\n\u001b[1;32m   1103\u001b[0m     mirostat_mode\u001b[38;5;241m=\u001b[39mmirostat_mode,\n\u001b[1;32m   1104\u001b[0m     mirostat_tau\u001b[38;5;241m=\u001b[39mmirostat_tau,\n\u001b[1;32m   1105\u001b[0m     mirostat_eta\u001b[38;5;241m=\u001b[39mmirostat_eta,\n\u001b[1;32m   1106\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39mfrequency_penalty,\n\u001b[1;32m   1107\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39mpresence_penalty,\n\u001b[1;32m   1108\u001b[0m     repeat_penalty\u001b[38;5;241m=\u001b[39mrepeat_penalty,\n\u001b[1;32m   1109\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[1;32m   1110\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[1;32m   1111\u001b[0m     grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[1;32m   1112\u001b[0m ):\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llama_cpp\u001b[38;5;241m.\u001b[39mllama_token_is_eog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mmodel, token):\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/llama_cpp/llama.py:723\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    725\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    726\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    727\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    741\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    742\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/llama_cpp/llama.py:561\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    557\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    559\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    560\u001b[0m )\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m~/Documents/prashantPer/suyoxxx/venv/lib/python3.10/site-packages/llama_cpp/_internals.py:317\u001b[0m, in \u001b[0;36m_LlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question = \"how to Preparing a dataset for supervised instruction finetuning?\"\n",
    "qa.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
